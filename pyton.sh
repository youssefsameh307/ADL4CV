#  python -m sample.generate --model_path ./save/control_CNN_weights/model000001000.pt --text_prompt "person walks up and squats slightly to pose a position and then turns right" --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/rightnow/control_cnn_weights/1000_crossed_leg_walk" --seed 16723 --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/!selectedconditions/legs crossed.jpg"
#  python -m sample.generate --model_path ./save/control_CNN_weights/model000001000.pt --text_prompt "person walks up and squats slightly to pose a position and then turns right" --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/rightnow/control_cnn_weights/1000_bearhug" --seed 16723 --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/!selectedconditions/bearhug.jpg"
# #  python -m sample.generate --model_path ./save/control_CNN_weights/model000002000.pt --text_prompt "person walks up and squats slightly to pose a position and then turns right" --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/rightnow/control_cnn_weights/2000_presentation_duck_condition" --seed 16723 --cond_path "pose.jpg"

# #  python -m sample.generate --model_path ./save/control_CNN_weights/model000003000.pt --text_prompt "person walks up and squats slightly to pose a position and then turns right" --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/rightnow/control_cnn_weights/3000_presentation_duck_condition" --seed 16723 --cond_path "pose.jpg"
 
#  python -m sample.generate --model_path ./save/control_CNN_weights/model000004000.pt --text_prompt "person walks up and squats slightly to pose a position and then turns right" --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/rightnow/control_cnn_weights/4000_crossed_leg_walk" --seed 16723 --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/!selectedconditions/legs crossed.jpg"
# python -m sample.generate --model_path ./save/control_CNN_weights/model000004000.pt --text_prompt "person walks up and squats slightly to pose a position and then turns right" --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/rightnow/control_cnn_weights/4000_bearhug" --seed 16723 --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/!selectedconditions/bearhug.jpg"
# #  python -m sample.generate --model_path ./save/control_CNN_weights/model000005000.pt --text_prompt "person walks up and squats slightly to pose a position and then turns right" --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/rightnow/control_cnn_weights/5000_presentation_duck_condition" --seed 16723 --cond_path "pose.jpg"

# #  python -m sample.generate --model_path ./save/control_CNN_weights/model000006000.pt --text_prompt "person walks up and squats slightly to pose a position and then turns right" --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/rightnow/control_cnn_weights/6000_presentation_duck_condition" --seed 16723 --cond_path "pose.jpg"

#  python -m sample.generate --model_path ./save/control_CNN_weights/model000007000.pt --text_prompt "person walks up and squats slightly to pose a position and then turns right" --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/rightnow/control_cnn_weights/7000_crossed_leg_walk" --seed 16723 --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/!selectedconditions/legs crossed.jpg"
# python -m sample.generate --model_path ./save/control_CNN_weights/model000007000.pt --text_prompt "person walks up and squats slightly to pose a position and then turns right" --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/rightnow/control_cnn_weights/7000_bearhug" --seed 16723 --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/!selectedconditions/bearhug.jpg"
# #  python -m sample.generate --model_path ./save/control_CNN_weights/model000008000.pt --text_prompt "person walks up and squats slightly to pose a position and then turns right" --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/rightnow/control_cnn_weights/8000_presentation_duck_condition" --seed 16723 --cond_path "pose.jpg"

# #  python -m sample.generate --model_path ./save/control_CNN_weights/model000009000.pt --text_prompt "person walks up and squats slightly to pose a position and then turns right" --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/rightnow/control_cnn_weights/9000_presentation_duck_condition" --seed 16723 --cond_path "pose.jpg"

#  python -m sample.generate --model_path ./save/control_CNN_weights/model000010000.pt --text_prompt "person walks up and squats slightly to pose a position and then turns right" --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/rightnow/control_cnn_weights/100000_crossed_leg_walk" --seed 16723 --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/!selectedconditions/legs crossed.jpg"
# python -m sample.generate --model_path ./save/control_CNN_weights/model000010000.pt --text_prompt "person walks up and squats slightly to pose a position and then turns right" --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/rightnow/control_cnn_weights/100000_bearhug" --seed 16723 --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/!selectedconditions/bearhug.jpg"





# python -m sample.generate --model_path ./save/control_CNN_weights/model000005000.pt --text_prompt "person walks up and squats slightly to pose a position, moving his hands" --seed 16723 --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/conditions/raiserighthand.jpg" --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/conditions/raiserighthand.jpg" --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/conditions/raiserighthand.jpg"



# python -m sample.generate --model_path ./save/control_CNN_weights/model000005000.pt --text_prompt "person walks up and squats slightly to pose a position, moving his hands " --seed 16723 --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/conditions/raiseslefthand.jpg" --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/conditions/raiseslefthand.jpg" --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/conditions/raiseslefthand.jpg"


# # left vs right wave
# python -m sample.generate --model_path ./save/controlformer_CNN_Control_10kx10k/model000005000.pt --text_prompt "a person waves goodbye " --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/presentation-candidates/wave-left-hand" --seed 16723 --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/conditions/a person raises their left arm and waves their hand side to side..jpg" --model_arch=mdm3
# python -m sample.generate --model_path ./save/controlformer_CNN_Control_10kx10k/model000005000.pt --text_prompt "a person waves goodbye " --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/presentation-candidates/wave-right-hand" --seed 16723 --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/conditions/a man lifts his right arm above head while bending elbow, then straightening the right elbow, then feeling around for head, and then straightening elbow again,.jpg" --model_arch=mdm3

# # left vs right kick 
# python -m sample.generate \
#     --model_path ./save/control_3CNN_64bs/model000006000.pt \
#     --model_arch mdmperfect2 \
#     --text_prompt "a person kicks someone" \
#     --seed 16723 \
#     --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/aNewConditions/0-kicks-left.jpg" \
#     --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/aNewConditions/0-kicks-left.jpg" \
#     --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/aNewConditions/0-kicks-left.jpg" \
#     --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/presentation-candidates/kicks-left"
    

    








# python -m sample.generate \
#     --model_path ./modela/diffcontrol_loss_Ccnn_conc_ours/model000000000.pt \
#     --model_arch mdmperfect2 \
#     --text_prompt "man walks forward " \
#     --seed 16723 \
#     --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/diffvgex2/image_137.png" \
#     --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/diffvgex2/image_9.png" \
#     --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/diffvgex2/image_9.png" \
#     --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/new-presentation-candidates/137_2*9_0k" \
#     --model_arch "mdm"


# python -m sample.generate \
#     --model_path ./modela/diffcontrol_loss_Ccnn_conc_ours/model000001000.pt \
#     --model_arch mdmperfect2 \
#     --text_prompt "man walks forward " \
#     --seed 16723 \
#     --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/diffvgex2/image_137.png" \
#     --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/diffvgex2/image_9.png" \
#     --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/diffvgex2/image_9.png" \
#     --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/new-presentation-candidates/137_2*9_0k" \
#     --model_arch "mdm"


# python -m sample.generate \
#     --model_path ./modela/diffcontrol_loss_Ccnn_conc_ours/model000002000.pt \
#     --model_arch mdmperfect2 \
#     --text_prompt "man walks forward " \
#     --seed 16723 \
#     --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/diffvgex2/image_137.png" \
#     --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/diffvgex2/image_9.png" \
#     --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/diffvgex2/image_9.png" \
#     --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/new-presentation-candidates/137_2*9_2k" \
#     --model_arch "mdm"



# python -m sample.generate \
#     --model_path ./modela/diffcontrol_loss_Ccnn_conc_ours/model000003000.pt \
#     --model_arch mdmperfect2 \
#     --text_prompt "man walks forward " \
#     --seed 16723 \
#     --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/diffvgex2/image_137.png" \
#     --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/diffvgex2/image_9.png" \
#     --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/diffvgex2/image_9.png" \
#     --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/new-presentation-candidates/137_2*9_3k"\
#     --model_arch "mdm"



# python -m sample.generate \
#     --model_path ./modela/diffcontrol_loss_Ccnn_conc_ours/model000004000.pt \
#     --model_arch mdmperfect2 \
#     --text_prompt "man walks forward " \
#     --seed 16723 \
#     --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/diffvgex2/image_137.png" \
#     --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/diffvgex2/image_9.png" \
#     --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/diffvgex2/image_9.png" \
#     --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/new-presentation-candidates/137_2*9_4k"\
#     --model_arch "mdm"


# python -m sample.generate \
#     --model_path ./modela/diffcontrol_loss_Ccnn_conc_ours/model000006000.pt \
#     --model_arch mdmperfect2 \
#     --text_prompt "man walks forward " \
#     --seed 16723 \
#     --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/diffvgex2/image_137.png" \
#     --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/diffvgex2/image_9.png" \
#     --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/diffvgex2/image_9.png" \
#     --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/new-presentation-candidates/137_2*9_6k"\
#     --model_arch "mdm"



# python -m sample.generate \
#     --model_path ./modela/diffcontrol_loss_Ccnn_conc_ours/model000008000.pt \
#     --model_arch mdmperfect2 \
#     --text_prompt "man walks forward " \
#     --seed 16723 \
#     --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/diffvgex2/image_137.png" \
#     --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/diffvgex2/image_9.png" \
#     --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/diffvgex2/image_9.png" \
#     --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/new-presentation-candidates/137_2*9_8k"\
#     --model_arch "mdm"



python -m sample.generate \
    --model_path ./modela/control_debug/model000003000.pt \
    --model_arch mdmperfect2 \
    --text_prompt "man walks forward " \
    --seed 16723 \
    --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_2.png" \
    --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_2.png" \
    --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_2.png" \
    --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/new-presentation-candidates/a11"\
    --model_arch "mdm"


python -m sample.generate \
    --model_path ./modela/control_debug/model000003000.pt \
    --model_arch mdmperfect2 \
    --text_prompt "man walks forward " \
    --seed 16723 \
    --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_5.png" \
    --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_5.png" \
    --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_5.png" \
    --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/new-presentation-candidates/a12"\
    --model_arch "mdm"

python -m sample.generate \
    --model_path ./modela/control_debug/model000003000.pt \
    --model_arch mdmperfect2 \
    --text_prompt "man walks forward " \
    --seed 16723 \
    --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_8.png" \
    --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_8.png" \
    --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_8.png" \
    --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/new-presentation-candidates/a13"\
    --model_arch "mdm"


# python -m sample.generate \
#     --model_path ./modela/control_debug/model000005000.pt \
#     --model_arch mdmperfect2 \
#     --text_prompt "man walks forward " \
#     --seed 16723 \
#     --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_2.png" \
#     --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_5.png" \
#     --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_8.png" \
#     --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/new-presentation-candidates/ns13"\
#     --model_arch "mdm"


# python -m sample.generate \
#     --model_path ./modela/control_debug/model000007000.pt \
#     --model_arch mdmperfect2 \
#     --text_prompt "man walks forward " \
#     --seed 16723 \
#     --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_2.png" \
#     --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_5.png" \
#     --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_8.png" \
#     --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/new-presentation-candidates/ns14"\
#     --model_arch "mdm"
















python -m sample.generate \
    --model_path ./modela/control_debug2/model000003000.pt \
    --model_arch mdmperfect2 \
    --text_prompt "man walks forward " \
    --seed 16723 \
    --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_2.png" \
    --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_2.png" \
    --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_2.png" \
    --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/new-presentation-candidates/ns21"\
    --model_arch "mdm"


python -m sample.generate \
    --model_path ./modela/control_debug2/model000003000.pt \
    --model_arch mdmperfect2 \
    --text_prompt "man walks forward " \
    --seed 16723 \
    --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_5.png" \
    --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_5.png" \
    --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_5.png" \
    --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/new-presentation-candidates/ns22"\
    --model_arch "mdm"


python -m sample.generate \
    --model_path ./modela/control_debug2/model000003000.pt \
    --model_arch mdmperfect2 \
    --text_prompt "man walks forward " \
    --seed 16723 \
    --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_8.png" \
    --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_8.png" \
    --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_8.png" \
    --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/new-presentation-candidates/ns23"\
    --model_arch "mdm"


# python -m sample.generate \
#     --model_path ./modela/control_debug2/model000005000.pt \
#     --model_arch mdmperfect2 \
#     --text_prompt "man walks forward " \
#     --seed 16723 \
#     --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_2.png" \
#     --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_5.png" \
#     --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_8.png" \
#     --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/new-presentation-candidates/ns23"\
#     --model_arch "mdm"


# python -m sample.generate \
#     --model_path ./modela/control_debug2/model000007000.pt \
#     --model_arch mdmperfect2 \
#     --text_prompt "man walks forward " \
#     --seed 16723 \
#     --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_2.png" \
#     --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_5.png" \
#     --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/batch_img/image_8.png" \
#     --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/new-presentation-candidates/ns24"\
#     --model_arch "mdm"











# python -m sample.generate \
#     --model_path ./save/control_3CNN_64bs/model000006000.pt --model_arch mdmperfect2 --text_prompt "man walks forward " --seed 16723 --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/presentation-candidates/handstand_middle_6k"


# python -m sample.generate \
#     --model_path ./save/control_3CNN_64bs/model000010000.pt \
#     --model_arch mdmperfect2 \
#     --text_prompt "man walks forward " \
#     --seed 16723 \
#     --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/!selectedconditions/sitting on ground.jpg" \
#     --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/conditions/0-kicks-right.jpg" \
#     --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/!selectedconditions/sitting on ground.jpg" \
#     --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/presentation-candidates/handstand_middle_10k"


# python -m sample.generate \
#     --model_path ./save/control_3CNN_64bs/model000006000.pt \
#     --model_arch mdmperfect2 \
#     --text_prompt "a person is making poses infront of a camera" \
#     --seed 16723 \
#     --cond_path "/home/youssefabdelazim307/adl4cv/ADL4CV/conditions/" \
#     --cond_path2 "/home/youssefabdelazim307/adl4cv/ADL4CV/conditions/" \
#     --cond_path3 "/home/youssefabdelazim307/adl4cv/ADL4CV/conditions/" \
#     --output_dir "/home/youssefabdelazim307/adl4cv/ADL4CV/presentation-candidates/dance-swain-pose"

